{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "import math\n",
    "import calendar\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "from itertools import combinations\n",
    "import datetime\n",
    "from datetime import datetime as dt\n",
    "from functools import reduce\n",
    "%pylab inline\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.chdir(r'''D:\\Coursera_ML\\Final Project\\Data''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Загрузка данных и новых признаков (ранее подготовленных)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_dt(x):\n",
    "    return pd.datetime.strptime(x,'%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped=pd.DataFrame()\n",
    "grouped_vars=pd.DataFrame()\n",
    "inregion=pd.DataFrame()\n",
    "for val in ['january','february','march','april','may','june']:\n",
    "    val1=pd.read_excel('Grouped_data_'+val+'.xlsx')\n",
    "    grouped=pd.concat([grouped,val1])\n",
    "    with open('new_vars_'+val+'.pickle','rb') as file:\n",
    "        val2=pickle.load(file)\n",
    "    grouped_vars=pd.concat([grouped_vars,val2])\n",
    "    with open('inregion_'+val+'.pickle','rb') as file:\n",
    "        val3=pickle.load(file)\n",
    "    inregion=pd.concat([inregion,val3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Следующие признаки были рассмотрены:\n",
    "#### 1) Признаки из сырых данных - средние число пассажиров, время поездки, дальность поездки, основная сумма оплаты (fare_amount) и доплаты за часы пик и ночное время (extra) и число машин приехавших в географическую зону.\n",
    "#### 2) Календарные - календарь празников США https://pypi.org/project/holidays/\n",
    "#### 3) Географические - идентификатор боро\n",
    "#### 4) Дополнительный признак - идентификатор аэропортов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "regs=grouped_vars.region_pickup.unique()\n",
    "grouped=grouped[grouped.region.apply(lambda x: x in regs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_arr=grouped.pickup_datehour.apply(to_dt).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inregion_corrected=inregion.groupby(['dropoff_datehour','region_dropoff'])[['N_arrive']].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inregion_corrected['dropoff_datehour']=inregion_corrected.dropoff_datehour.apply(to_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inregion_corrected=inregion_corrected[(inregion_corrected.dropoff_datehour<=max(date_arr))&(inregion_corrected.dropoff_datehour>=min(date_arr))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inregion_corrected.columns=list(grouped_vars.columns[:2])+['N_arrive']\n",
    "grouped_vars['pickup_datehour']=grouped_vars['pickup_datehour'].apply(to_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_vars=grouped_vars.merge(inregion_corrected,how='outer',on=list(grouped_vars.columns[:2])).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lst=list(grouped.columns)\n",
    "lst[1]='region_pickup'\n",
    "grouped.columns=lst\n",
    "grouped['pickup_datehour']=grouped.pickup_datehour.apply(to_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_all=grouped.merge(all_vars,how='outer',on=list(all_vars.columns[:2])).fillna(0)\n",
    "data_all.index=data_all.pickup_datehour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regs=data_all.region_pickup.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Посчитаем ошибку в мае без учета и с учетом новых признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_data={}\n",
    "for val in data_all.region_pickup.unique():\n",
    "    form=pd.DataFrame(0,index=date_arr,columns=list(data_all.columns[2:]))\n",
    "    temp=data_all[data_all.region_pickup==val]\n",
    "    form.update(temp)\n",
    "    y=form[['N_trips']]\n",
    "    new_data[val]=[y,form[['N_arrive','trip_distance']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exog['week_day']=[x.weekday() for x in exog.index]\n",
    "exog['hour']=[x.hour for x in exog.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outer_periods(step,p):\n",
    "    def sum_periods(df):\n",
    "        vals=df.values\n",
    "        ar0=np.array([np.array([np.nan]*len(vals[0])) for x in range(p+step-1)])\n",
    "        ar1=np.array([np.apply_along_axis(sum,0,vals[x-p-step+1:x]) for x in range(p+step-1,len(vals))])\n",
    "        res=pd.DataFrame(np.vstack([ar0,ar1]),index=df.index,columns=df.columns)\n",
    "        return res\n",
    "    return sum_periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in new_data:\n",
    "    dat=new_data[val][0]\n",
    "    shifted=pd.concat([pd.DataFrame(dat.shift(periods=i).values,\\\n",
    "                                    columns=dat.columns+\\\n",
    "                                    np.array(['_'+str(i)]*len(dat.columns)),\\\n",
    "                index=dat.index) for i in range(1,7)],axis=1)\n",
    "    shifted_seasonal=pd.concat([pd.DataFrame(dat.shift(periods=i*24).values,\\\n",
    "                                    columns=dat.columns+\\\n",
    "                                    np.array(['_'+str(i*24)]*len(dat.columns)),\\\n",
    "                index=dat.index) for i in range(1,3)],axis=1)\n",
    "    sum_halfday=outer_periods(1,12)(dat)\n",
    "    sum_halfday.columns=[x+'_sum_12' for x in sum_halfday.columns]\n",
    "    sum_day=outer_periods(1,24)(dat)\n",
    "    sum_day.columns=[x+'_sum_24' for x in sum_day.columns]\n",
    "    shifted_all=pd.concat([shifted,shifted_seasonal,sum_halfday,sum_day],axis=1)\n",
    "    new_data[val].append(shifted_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_csv=pd.read_csv(r'''TRUE_PREDS_ALL.csv''',engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recover_ind(x):\n",
    "    date,hour,step=x.split('_')[1:]\n",
    "    if len(hour)==1: hour='0'+hour\n",
    "    time=hour+':00:00'\n",
    "    actual=dt.strptime(date+' '+time,'%Y-%m-%d %H:%M:%S')+datetime.timedelta(hours=int(step))\n",
    "    return actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_csv.index=preds_csv.id.apply(recover_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_csv['step']=preds_csv.id.apply(lambda x: int(x.split('_')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_csv['reg']=preds_csv.id.apply(lambda x: int(x.split('_')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_inds=pd.Series(np.nan,index=date_arr)\n",
    "def extract_preds(reg,step):\n",
    "    data=preds_csv[(preds_csv['reg']==reg)&(preds_csv['step']==step)][['y','id']]\n",
    "    res=total_inds\n",
    "    res[data.index]=data['y']\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mdot(*args):\n",
    "    st=args[0]\n",
    "    for val in args[1:]:\n",
    "        st=np.dot(st,val)\n",
    "    return st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in exog.week_day.unique()[1:]:\n",
    "    exog['week_day'+str(val)]=exog.week_day.apply(lambda x: int(x==val))\n",
    "for val in exog.hour.unique()[1:]:\n",
    "    exog['hour'+str(val)]=exog.hour.apply(lambda x: int(x==val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exog=exog.drop(['week_day','hour'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import holidays\n",
    "us_holidays = holidays.UnitedStates()\n",
    "def inhol(x):\n",
    "    return int(x in us_holidays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "exog['hol']=[inhol(x) for x in exog.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exog2=exog.drop(['hol'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_april=np.array([x<=pd.datetime(2016,4,30,23) for x in exog.index]).argmin()\n",
    "len_may=np.array([x<=pd.datetime(2016,5,31,23) for x in exog.index]).argmin()\n",
    "len_june=len(exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge\n",
    "def outer_linreg(estimator,lambd,ind0,ind1,ind2,ind3,mode='score',old=True):\n",
    "    def linreg(reg):\n",
    "        y_all=new_data[reg][0]['N_trips']\n",
    "        dat_all=new_data[reg][1]\n",
    "        shifts=new_data[reg][2]\n",
    "        res=np.array([])\n",
    "        if mode=='score':\n",
    "            for step in range(1,7):\n",
    "                preds=extract_preds(reg,step)\n",
    "                if old:\n",
    "                    X_all=pd.concat([exog2,shifts,preds],axis=1)\n",
    "                else: \n",
    "                    X_all=pd.concat([exog,shifts,dat_all,preds],axis=1)\n",
    "                X=X_all.iloc[ind0:ind1,:].dropna(axis=0)\n",
    "                y=y_all[X.index].values\n",
    "                X=X.values\n",
    "                model=eval(estimator)(alpha=lambd).fit(X,y)\n",
    "                X_test=X_all.iloc[ind2+step-1:ind3-6+step,:].dropna(axis=0)\n",
    "                y_test=y_all[X_test.index].values\n",
    "                X_test=X_test.values\n",
    "                prd=mdot(X_test,model.coef_)\n",
    "                res=np.append(res,np.abs(y_test-prd))\n",
    "            return res\n",
    "        elif mode=='data':\n",
    "            new_preds=pd.DataFrame()\n",
    "            for step in range(1,7):\n",
    "                preds=extract_preds(reg,step)\n",
    "                if old:\n",
    "                    X_all=pd.concat([exog2,shifts,preds],axis=1)\n",
    "                else: \n",
    "                    X_all=pd.concat([exog,shifts,dat_all,preds],axis=1)\n",
    "                X=X_all.iloc[ind0:ind1,:].dropna(axis=0)\n",
    "                y=y_all[X.index].values\n",
    "                X=X.values\n",
    "                model=eval(estimator)(alpha=lambd).fit(X,y)\n",
    "                X_test=X_all.iloc[ind2+step-1:ind3-6+step,:].dropna(axis=0)\n",
    "                data=preds_csv[(preds_csv['reg']==reg)&(preds_csv['step']==step)].loc[list(X_test.index),['id']]\n",
    "                y_test=y_all[X_test.index].values\n",
    "                X_test=X_test.values\n",
    "                prd=mdot(X_test,model.coef_)\n",
    "                data['y']=prd\n",
    "                res=np.append(res,np.abs(y_test-prd))\n",
    "                new_preds=pd.concat([new_preds,data])\n",
    "            return res,new_preds\n",
    "    return linreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_old=outer_linreg('Lasso',1,0,len_april,len_april,len_may,mode='score',old=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists_old=[f_old(x) for x in new_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка в мае с использованием старых признаков=24.328145594212064\n"
     ]
    }
   ],
   "source": [
    "print('Ошибка в мае с использованием старых признаков={}'.format(np.mean(lists_old)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_new=outer_linreg('Lasso',1,0,len_april,len_april,len_may,mode='score',old=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists_new=[f_new(x) for x in new_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка в мае с добавлением новых признаков=20.634259379157808\n"
     ]
    }
   ],
   "source": [
    "print('Ошибка в мае с добавлением новых признаков={}'.format(np.mean(lists_new)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Таким образом ошибка в мае снизилась с 24.3 до 20.6. Теперь посчитаем ошибку в июне и осуществим сабмишн."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_new=outer_linreg('Lasso',1,0,len_may,len_may,len_june,mode='data',old=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists_new=[f_new(x) for x in new_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "err=np.mean([x[0] for x in lists_new])\n",
    "data=pd.concat([x[1] for x in lists_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка в июне с добавлением новых признаков=19.72713578467824\n"
     ]
    }
   ],
   "source": [
    "print('Ошибка в июне с добавлением новых признаков={}'.format(np.mean(err)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ошибка в июне составила 19.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('results_final6.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ссылка на сабмишн: https://www.kaggle.com/c/yellowtaxi/submissions?sortBy=date&group=all&page=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
