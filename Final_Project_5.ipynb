{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "import math\n",
    "import calendar\n",
    "from matplotlib import pyplot as plt\n",
    "%pylab inline\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.chdir(r'''D:\\Coursera_ML\\Final Project\\Data''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Загрузка данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_january=pd.read_excel(r'''Grouped_data_january.xlsx''')\n",
    "data_february=pd.read_excel(r'''Grouped_data_february.xlsx''')\n",
    "data_march=pd.read_excel(r'''Grouped_data_march.xlsx''')\n",
    "data_april=pd.read_excel(r'''Grouped_data_april.xlsx''')\n",
    "data_may=pd.read_excel(r'''Grouped_data_may.xlsx''')\n",
    "data_june=pd.read_excel(r'''Grouped_data_june.xlsx''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regions=(data_may.groupby('region').sum()['N_trips']/24/31)[data_may.groupby('region').sum()['N_trips']/24/31>=5].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_january=data_january[data_january.region.apply(lambda x: x in regions)]\n",
    "data_february=data_february[data_february.region.apply(lambda x: x in regions)]\n",
    "data_march=data_march[data_march.region.apply(lambda x: x in regions)]\n",
    "data_april=data_april[data_april.region.apply(lambda x: x in regions)]\n",
    "data_may=data_may[data_may.region.apply(lambda x: x in regions)]\n",
    "data_june=data_june[data_june.region.apply(lambda x: x in regions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train=pd.concat([data_january,data_february,data_march,data_april])\n",
    "data_train.index=data_train.pickup_datehour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train_may=pd.concat([data_january,data_february,data_march,data_april,data_may])\n",
    "data_train_may.index=data_train_may.pickup_datehour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Преобразование данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aggregated_data=pd.DataFrame(np.array([str(x)+'_'+str(y) for x in data_train.pickup_datehour.unique() for y in regions]).reshape(len(data_train.pickup_datehour.unique()),len(regions)),columns=regions,index=data_train.pickup_datehour.unique()).applymap(lambda x: x.split('_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aggregated_data_may=pd.DataFrame(np.array([str(x)+'_'+str(y) for x in data_train_may.pickup_datehour.unique() for y in regions]).reshape(len(data_train_may.pickup_datehour.unique()),len(regions)),columns=regions,index=data_train_may.pickup_datehour.unique()).applymap(lambda x: x.split('_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vlookup(data):\n",
    "    def vlp(x):\n",
    "        try:\n",
    "            val=data.loc[x[0],:][data.loc[x[0],:].region==int(x[1])]['N_trips'][0]\n",
    "        except:\n",
    "            val=0\n",
    "        return val\n",
    "    return vlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aggregated=aggregated_data.applymap(vlookup(data_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aggregated_may=aggregated_data_may.applymap(vlookup(data_train_may))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aggregated_stand=aggregated.apply(lambda x: (x-np.mean(x))/np.std(x,ddof=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aggregated_stand_may=aggregated_may.apply(lambda x: (x-np.mean(x))/np.std(x,ddof=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T=np.arange(1,len(aggregated_stand)+1)\n",
    "exog=pd.DataFrame()\n",
    "K=5\n",
    "for i in range(1,K+1):\n",
    "    exog['sin_'+str(i)]=np.sin(T*2*math.pi*i/168)\n",
    "    exog['cos_'+str(i)]=np.cos(T*2*math.pi*i/168)\n",
    "exog['Intercept']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T=np.arange(1,len(aggregated_stand_may)+1)\n",
    "exog_may=pd.DataFrame()\n",
    "K=5\n",
    "for i in range(1,K+1):\n",
    "    exog_may['sin_'+str(i)]=np.sin(T*2*math.pi*i/168)\n",
    "    exog_may['cos_'+str(i)]=np.cos(T*2*math.pi*i/168)\n",
    "exog_may['Intercept']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_june.index=data_june.pickup_datehour\n",
    "aggregated_data_june=pd.DataFrame(np.array([str(x)+'_'+str(y) for x in data_june.pickup_datehour.unique() for y in regions]).reshape(len(data_june.pickup_datehour.unique()),len(regions)),columns=regions,index=data_june.pickup_datehour.unique()).applymap(lambda x: x.split('_'))\n",
    "aggregated_june=aggregated_data_june.applymap(vlookup(data_june))\n",
    "aggregated_stand_june=aggregated_june.apply(lambda x: (x-np.mean(x))/np.std(x,ddof=1))\n",
    "T_june=np.arange(len(exog_may)+1,len(exog_may)+1+len(aggregated_stand_june))\n",
    "exog_june=pd.DataFrame()\n",
    "K=5\n",
    "for i in range(1,K+1):\n",
    "    exog_june['sin_'+str(i)]=np.sin(T_june*2*math.pi*i/168)\n",
    "    exog_june['cos_'+str(i)]=np.cos(T_june*2*math.pi*i/168)\n",
    "exog_june['Intercept']=1\n",
    "exog_final=pd.concat([exog_may,exog_june])\n",
    "exog_final.index=np.arange(len(exog_final))\n",
    "aggregated_stand_final=pd.concat([aggregated_stand_may,aggregated_stand_june])\n",
    "aggregated_final=pd.concat([aggregated_may,aggregated_june])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Загрузка SARIMA прогнозов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_csv=pd.read_csv(r'''TRUE_PREDS_ALL.csv''',engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1075_2016-01-03_23_1</td>\n",
       "      <td>42.080105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1075_2016-01-04_0_1</td>\n",
       "      <td>7.405356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1075_2016-01-04_1_1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1075_2016-01-04_2_1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1075_2016-01-04_3_1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id          y\n",
       "0  1075_2016-01-03_23_1  42.080105\n",
       "1   1075_2016-01-04_0_1   7.405356\n",
       "2   1075_2016-01-04_1_1   0.000000\n",
       "3   1075_2016-01-04_2_1   0.000000\n",
       "4   1075_2016-01-04_3_1   0.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Создание признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exog_final.index=aggregated_final.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Возьмем день недели и час из второго подпункта первого пункта задания как категориальные признаки - остальные признаки этого подпункта логически не имеют смысла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import calendar\n",
    "def w_day(x):\n",
    "    date=x.split(' ')[0]\n",
    "    y,m,d=np.array(date.split('-')).astype(int)\n",
    "    res=calendar.weekday(y,m,d)\n",
    "    return res\n",
    "exog_final['week_day']=pd.Series(exog_final.index,index=exog_final.index).apply(w_day)\n",
    "exog_final['hour']=pd.Series(exog_final.index,index=exog_final.index).apply(lambda x: int(x.split(' ')[1].split(':')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Возьмем $K=6$ и $K_d=2$, так как это рекомендовалось в задании."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shifted=pd.concat([pd.DataFrame(aggregated_final.shift(periods=i).values,\\\n",
    "                                columns=aggregated_final.columns.astype(str)+\\\n",
    "                                np.array(['_'+str(i)]*len(aggregated_final.columns)),\\\n",
    "            index=aggregated_final.index) for i in range(1,7)],axis=1)\n",
    "shifted_seasonal=pd.concat([pd.DataFrame(aggregated_final.shift(periods=i*24).values,\\\n",
    "                                columns=aggregated_final.columns.astype(str)+\\\n",
    "                                np.array(['_'+str(i*24)]*len(aggregated_final.columns)),\\\n",
    "            index=aggregated_final.index) for i in range(1,3)],axis=1)\n",
    "shifted_all=pd.concat([shifted,shifted_seasonal],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Возьмем суммарное количество поездок за предшествующиe полдня и день. За месяц и неделю не будем брать, это выкинет много начальных наблюдений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def outer_periods(p):\n",
    "    def sum_periods(x):\n",
    "        pos=(aggregated_final.index==x.name).argmax()\n",
    "        if pos<p: return pd.Series([np.nan]*len(x),index=aggregated_final.columns)\n",
    "        else:\n",
    "            ind=np.arange(pos-p,pos,1)\n",
    "            return aggregated_final.iloc[ind,:].apply(sum)\n",
    "    return sum_periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum_day=aggregated_final.apply(outer_periods(24),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum_halfday=aggregated_final.apply(outer_periods(12),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recover_ind(x):\n",
    "    date,hour,step=x.split('_')[1:]\n",
    "    if len(hour)==1: hour='0'+hour\n",
    "    time=hour+':00:00'\n",
    "    actual=str(dt.strptime(date+' '+time,'%Y-%m-%d %H:%M:%S')+datetime.timedelta(hours=int(step)))\n",
    "    return actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_csv.index=preds_csv.id.apply(recover_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_csv['step']=preds_csv.id.apply(lambda x: int(x.split('_')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_csv['reg']=preds_csv.id.apply(lambda x: int(x.split('_')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_csv=preds_csv.drop(['pred_data'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "total_inds=pd.Series(np.nan,index=aggregated_final.index)\n",
    "\n",
    "def extract_preds(reg,step):\n",
    "    data=preds_csv[(preds_csv['reg']==reg)&(preds_csv['step']==step)][['y','id']]\n",
    "    res=total_inds\n",
    "    res[data.index]=data['y']\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for val in exog_final.week_day.unique()[1:]:\n",
    "    exog_final['week_day'+str(val)]=exog_final.week_day.apply(lambda x: int(x==val))\n",
    "for val in exog_final.hour.unique()[1:]:\n",
    "    exog_final['hour'+str(val)]=exog_final.hour.apply(lambda x: int(x==val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exog_final=exog_final.drop(['week_day','hour'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mdot(*args):\n",
    "    st=args[0]\n",
    "    for val in args[1:]:\n",
    "        st=np.dot(st,val)\n",
    "    return st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge\n",
    "def outer_linreg(estimator,lambd,ind,ind2,mode='score'):\n",
    "    def linreg(x):\n",
    "        reg=x.name\n",
    "        colnames=shifted_all.columns[pd.Series(shifted_all.columns).apply(lambda x: x.split('_')[0]==str(reg))]\n",
    "        ar=shifted_all[colnames]\n",
    "        res=np.array([])\n",
    "        if mode=='score':\n",
    "            for step in range(1,7):\n",
    "                preds=extract_preds(reg,step)\n",
    "                X_all=pd.concat([exog_final,sum_halfday[[reg]],sum_day[[reg]],ar,preds],axis=1)\n",
    "                X=X_all.iloc[:ind,:].dropna(axis=0)\n",
    "                y=x[X.index].values\n",
    "                X=X.values\n",
    "                model=eval(estimator)(alpha=lambd).fit(X,y)\n",
    "                X_test=X_all.iloc[ind:ind2,:].dropna(axis=0)\n",
    "                y_test=x[X_test.index].values\n",
    "                X_test=X_test.values\n",
    "                prd=mdot(X_test,model.coef_)\n",
    "                res=np.append(res,np.abs(y_test-prd))\n",
    "            val=np.sum(res)\n",
    "            return val\n",
    "        elif mode=='data':\n",
    "            new_preds=pd.DataFrame()\n",
    "            for step in range(1,7):\n",
    "                preds=extract_preds(reg,step)\n",
    "                X_all=pd.concat([exog_final,sum_halfday[[reg]],sum_day[[reg]],ar,preds],axis=1)\n",
    "                X=X_all.iloc[:ind,:].dropna(axis=0)\n",
    "                y=x[X.index].values\n",
    "                X=X.values\n",
    "                model=eval(estimator)(alpha=lambd).fit(X,y)\n",
    "                X_test=X_all.iloc[ind+step-1:ind2-6+step,:].dropna(axis=0)\n",
    "                data=preds_csv[(preds_csv['reg']==reg)&(preds_csv['step']==step)].loc[list(X_test.index),['id']]\n",
    "                y_test=x[X_test.index].values\n",
    "                X_test=X_test.values\n",
    "                prd=mdot(X_test,model.coef_)\n",
    "                data['y']=prd\n",
    "                res=np.append(res,np.abs(y_test-prd))\n",
    "                new_preds=pd.concat([new_preds,data])\n",
    "            val=np.sum(res)\n",
    "            return val,new_preds         \n",
    "            \n",
    "    return linreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Проведем оценку параметров регрессии c L1 и L2 регуляризаторами для каждого региона в отдельности. На данных до апреля включительно необходимо ответить на два вопроса: 1) какой регуляризатор ''лучше''? 2) каким взять $\\lambda$?. Иными словами, необходимо настроить гиперпараметры. Рассмотрим сетку  $\\lambda \\in \\{1,5,10,20\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params=product(['Ridge','Lasso'],[1,5,10,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vals={}\n",
    "for method,lambd in params:\n",
    "    f=outer_linreg(method,lambd,len(exog),len(exog_may),mode='score')\n",
    "    res=sum(aggregated_final.apply(f))/102/739/6\n",
    "    vals[(method,lambd)]=res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ниже приведены средние абсолютные отклонения в мае для моделей, обученных на данных до апреля. Неделю назад $MAE\\approx 26$, значит каждая, из нижеприведенных моделей показывает лучший результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('Lasso', 1): 21.097122121541116,\n",
       " ('Lasso', 5): 22.815161260498083,\n",
       " ('Lasso', 10): 23.106258417162994,\n",
       " ('Lasso', 20): 23.350874330272944,\n",
       " ('Ridge', 1): 23.604211311053366,\n",
       " ('Ridge', 5): 21.68516382310419,\n",
       " ('Ridge', 10): 21.28045332348924,\n",
       " ('Ridge', 20): 21.050894457842634}"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Отберем две модели: ('Lasso', 1) и ('Ridge', 20), оценим их на данных до мая и построим прогнозы на июнь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "vals_june={}\n",
    "vals_june_data={}\n",
    "for method,lambd in [('Lasso', 1),('Ridge', 20)]:\n",
    "    f=outer_linreg(method,lambd,len(exog_may),len(exog_final),mode='data')\n",
    "    estimates=aggregated_final.apply(f)\n",
    "    errors=estimates.apply(lambda x: x[0])\n",
    "    hats=estimates.apply(lambda x: x[1])\n",
    "    preds=reduce(lambda x,y:pd.concat([x,y]),hats)\n",
    "    res=sum(errors)/102/715/6\n",
    "    vals_june[(method,lambd)]=res\n",
    "    vals_june_data[(method,lambd)]=preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ниже результаты, и они практически одинаковы. Выберем Лассо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('Lasso', 1): 20.13099501584597, ('Ridge', 20): 20.140670551020992}"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals_june"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vals_june_data[('Lasso', 1)].to_csv('Lasso_preds.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ссылка на сабмишн.\n",
    "https://www.kaggle.com/c/yellowtaxi/submissions?sortBy=date&group=all&page=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
